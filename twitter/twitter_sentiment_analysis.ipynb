{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import dataset\n",
    "df = pd.read_csv(\"../datasets/tweets.csv\")\n",
    "df = df.dropna()\n",
    "df[\"category\"] = df[\"category\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{df.info()}\\n\")\n",
    "print(f\"Target values: {df['category'].unique()} \\n\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'modi like woman like sandra'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean data\n",
    "stop_words = stopwords.words('english')\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "tokenizer = TweetTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def clean_text(text: str):\n",
    "\n",
    "    # lowercase string\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove stop words\n",
    "    text = \" \".join([word for word in str(\n",
    "        text).split() if word not in stop_words])\n",
    "\n",
    "    # remove urls\n",
    "    text = re.sub('((www.[^s]+)|(https?://[^s]+))', ' ', text)\n",
    "\n",
    "    # remove punctuations\n",
    "    text = text.translate(translator)\n",
    "\n",
    "    # remove repeating characters\n",
    "    text = re.sub(r'(.)1+', r'1', text)\n",
    "\n",
    "    # remove numbers\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "\n",
    "    # tokenize text\n",
    "    text: list[str] = tokenizer.tokenize(text)\n",
    "\n",
    "    # normalize with lemmatizer\n",
    "    tokens = []\n",
    "    for token, tag in pos_tag(text):\n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "        tokens.append(token)\n",
    "    text = tokens\n",
    "\n",
    "    text = \" \".join(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "clean_text(\"modi like women like sandra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162975</th>\n",
       "      <td>crore pay neerav modi recover congress leader ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162976</th>\n",
       "      <td>dear rss terrorist payal gawar modi kill plus ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162977</th>\n",
       "      <td>cover interaction forum leave</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162978</th>\n",
       "      <td>big project come india modi dream project happ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162979</th>\n",
       "      <td>ever listen like gurukul discipline maintain e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  category\n",
       "162975  crore pay neerav modi recover congress leader ...        -1\n",
       "162976  dear rss terrorist payal gawar modi kill plus ...        -1\n",
       "162977                      cover interaction forum leave         0\n",
       "162978  big project come india modi dream project happ...         0\n",
       "162979  ever listen like gurukul discipline maintain e...         1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_text\"] = df[\"clean_text\"].map(lambda x: clean_text(x))\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing datasets\n",
    "x = df[\"clean_text\"]\n",
    "y = df[\"category\"]\n",
    "# print(x.tail())\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  500000\n"
     ]
    }
   ],
   "source": [
    "### fit tf-idf vector\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(x_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names_out ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### transform train and test dataset\n",
    "x_train = vectoriser.transform(x_train)\n",
    "x_test = vectoriser.transform(x_test)\n",
    "\n",
    "# save vectorizer\n",
    "with open(\"../models/tweet_feature_extractor.pickle\", \"wb\") as file:\n",
    "    pickle.dump(vectoriser, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB\n",
      "Accuracy:\t0.7107647624307132\n"
     ]
    }
   ],
   "source": [
    "b_naive_bayes_model = BernoulliNB()\n",
    "b_naive_bayes_model.fit(x_train, y_train)\n",
    "nb_y_pred = b_naive_bayes_model.predict(x_test)\n",
    "print(f\"BernoulliNB\\nAccuracy:\\t{accuracy_score(y_test, nb_y_pred)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Accuracy:\t0.8587674623141274\n"
     ]
    }
   ],
   "source": [
    "svc_model = LinearSVC()\n",
    "svc_model.fit(x_train, y_train)\n",
    "svc_y_pred = svc_model.predict(x_test)\n",
    "print(f\"SVM\\nAccuracy:\\t{accuracy_score(y_test, svc_y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = vectoriser.transform([\"when modi promised “minimum government maximum governance” expected him begin the difficult job reforming the state why does take years get justice state should and not business and should exit psus and temples\"])\n",
    "svc_model.predict(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy:\t0.8488269824712115\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model = LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1)\n",
    "logistic_regression_model.fit(x_train, y_train)\n",
    "lr_y_pred = logistic_regression_model.predict(x_test)\n",
    "print(f\"Logistic Regression\\nAccuracy:\\t{accuracy_score(y_test, lr_y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "xgb_y_train = encoder.transform(y_train)\n",
    "xgb_y_test = encoder.transform(y_test)\n",
    "\n",
    "xgboost_model = XGBClassifier(n_jobs=-1)\n",
    "xgboost_model.fit(x_train, xgb_y_train)\n",
    "xgb_y_pred = xgboost_model.predict(x_test)\n",
    "print(f\"XGBoost\\nAccuracy:\\t{accuracy_score(xgb_y_test, xgb_y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "random_forest_model.fit(x_train, y_train)\n",
    "rf_y_pred = random_forest_model.predict(x_test)\n",
    "print(f\"Random Forest\\nAccuracy:\\t{accuracy_score(y_test, rf_y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "with open(\"../models/twitter_sentiment_model.pickle\", \"wb\") as file:\n",
    "    pickle.dump(svc_model, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab65a6a126614c4d8a09c3bb162b3d2e4f4a949753c6f0f735c7c1fe269df83b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
